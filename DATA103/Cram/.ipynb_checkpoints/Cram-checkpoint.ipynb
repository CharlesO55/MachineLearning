{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d39080-e789-4ea8-b304-e551e014335d",
   "metadata": {},
   "source": [
    "# 0.0 Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169c9f4-889b-40b8-b965-f4ae3cedfb8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### fill_na\n",
    "    df['Age'] = df['Age'].fillna(df.Age.mean())\n",
    "    df['Color'] = df['Color'].fillna(df.Color.mode()[0])\n",
    "\n",
    "### machine_learning\n",
    "    from sklearn.impute import KNNImputer\n",
    "    X = [[1, 2, np.nan], [3, 4, 3], [np.nan, 6, 5], [8, 8, 7]]\n",
    "    df = pd.DataFrame(X, columns=['feat_1', 'feat_2', 'feat_3'])\n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be21fd-cd06-4b8f-9e98-7120ddf9f78b",
   "metadata": {},
   "source": [
    "# 0.1 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e00245-3aef-402f-b617-ef2cc63cac2e",
   "metadata": {},
   "source": [
    "\n",
    "### Forward (Sequential Feature Selection)\n",
    "    from sklearn.feature_selection import SequentialFeatureSelector\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    sfs = SequentialFeatureSelector(knn, n_features_to_select=.8)\n",
    "    sfs.fit(X_train, y_train)\n",
    "    X_train.columns[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0728932-ecf2-4b6f-9a0c-0d70e5dc9606",
   "metadata": {},
   "source": [
    "\n",
    "### Backward (Recursive Feature Elimination)\n",
    "    from sklearn.feature_selection import RFE, RFECV\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    estimator = LogisticRegression()\n",
    "    selector = RFE(estimator, n_features_to_select=7, step=1)\n",
    "    selector.fit(X_train, y_train)\n",
    "\n",
    "    X_train.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182ea15-d7ed-4c90-a796-ae44631ecbdb",
   "metadata": {},
   "source": [
    "# 0.2 Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d0ff9c-5ee7-4f60-bd36-853fdc2506db",
   "metadata": {},
   "source": [
    "\n",
    "### Over sampling\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "\n",
    "    oversampler = SMOTE(sampling_strategy=0.5, k_neighbors=6)\n",
    "    X_over, y_over = oversampler.fit_resample(X_train, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b645ac-8dcf-4cc9-8e4d-64f89eccec69",
   "metadata": {},
   "source": [
    "# 1 Log Reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40059407-9aba-4db4-b14c-d31abac9bebb",
   "metadata": {},
   "source": [
    "## Params\n",
    "    param_grid = {\n",
    "        'C': [0.1, 0.001, 0.0001, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "    }\n",
    "\n",
    "## Scorers\n",
    "    scorers = {\n",
    "        'precision_score': make_scorer(precision_score),\n",
    "        'recall_score': make_scorer(recall_score),\n",
    "        'accuracy_score': make_scorer(accuracy_score),\n",
    "    }\n",
    "\n",
    "## Hyper Param Search\n",
    "    clf_grid = GridSearchCV(LogisticRegression(solver=\"liblinear\"), param_grid, refit = True, verbose = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf5cc4-342b-4da6-b3a8-aa3285a07740",
   "metadata": {},
   "source": [
    "# 2 SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2f9ba6-9375-4491-a4d2-66b969f84e73",
   "metadata": {},
   "source": [
    "## Params\n",
    "    param_grid = {\n",
    "        'C': [0.1, 0.001, 0.0001, 10, 100, 1000],\n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001, 10, 100],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "\n",
    "## Scorers\n",
    "    scorers = {\n",
    "        'precision_score': make_scorer(precision_score),\n",
    "        'recall_score': make_scorer(recall_score),\n",
    "        'accuracy_score': make_scorer(accuracy_score),\n",
    "    }\n",
    "\n",
    "## Hyper Param Search\n",
    "    clf_grid = GridSearchCV(SVC(), param_grid, scoring=scorers, cv=10, refit='precision_score', verbose = 3)\n",
    "\n",
    "## Time Series\n",
    "    RandomizedSearchCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
    "                   estimator=SVR(),\n",
    "                   param_distributions={'C': [0.1, 1, 10, 100, 1000],\n",
    "                                        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                                        'kernel': ['rbf']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b64e1-436e-4c14-a878-1a799d803149",
   "metadata": {},
   "source": [
    "# 3 Trees and Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4780c2c-6da2-4328-b88e-6c31bf35067c",
   "metadata": {},
   "source": [
    "\n",
    "## Params\n",
    "    param_grid = {\n",
    "        'max_depth': range(5,20),\n",
    "        'min_samples_split': np.arange(0.1,.6,.1),\n",
    "        'min_samples_leaf': np.arange(0.1,.6,.1)\n",
    "    }\n",
    "\n",
    "## Scorers\n",
    "    scorers = {\n",
    "        'precision_score': make_scorer(precision_score),\n",
    "        'recall_score': make_scorer(recall_score),\n",
    "        'accuracy_score': make_scorer(accuracy_score),\n",
    "    }\n",
    "\n",
    "## Hyper Param Search\n",
    "\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn import tree\n",
    "    clf_grid = GridSearchCV(SVC(), param_grid, scoring=scorers, cv=10, refit='precision_score', verbose = 3)\n",
    "\n",
    "## Plotting Trees\n",
    "\n",
    "    regressor = DecisionTreeRegressor(max_depth=5,random_state=0)\n",
    "    regressor.fit(X_train.head(100), y_train.head(100)) # doing this for visualization purposes only\n",
    "    print(f\"R-squared {regressor.score(X_train.head(100), y_train.head(100))}\")\n",
    "    fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (15,15), dpi=500)\n",
    "    tree.plot_tree(regressor, feature_names=X_train.columns, filled=True);\n",
    "\n",
    "## Time Series\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    \n",
    "    param_grid = {\n",
    "        'max_depth': range(5,20),\n",
    "        'min_samples_split': np.arange(0.1,.6,.1),\n",
    "        'min_samples_leaf': np.arange(0.1,.6,.1)\n",
    "    }\n",
    "    \n",
    "    tss = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
    "    regressor = DecisionTreeRegressor()\n",
    "    reg = RandomizedSearchCV(regressor, param_grid, cv=tss, n_iter=100)\n",
    "    reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f97502-7f35-442a-9471-4fe38ab7e792",
   "metadata": {},
   "source": [
    "# 4 Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155bb5a3-84fb-498e-8c64-3717ac344642",
   "metadata": {},
   "source": [
    "\n",
    "## Stacking\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "    # WHERE lr_model and knn_model have been trained.\n",
    "    \n",
    "    eclf = VotingClassifier([('lr', lr_model), ('knn', knn_model)])\n",
    "    eclf.fit(X_train, y_train)\n",
    "\n",
    "## Grid Searched Stacking\n",
    "    param_grid = {\n",
    "        'lr__C': [0.1, 1, 10],\n",
    "        \"lr__penalty\": [\"l1\", \"l2\"], \n",
    "        \"lr__solver\": [\"liblinear\"],\n",
    "        \"knn__n_neighbors\": range(5,20)\n",
    "    }\n",
    "    \n",
    "    eclf = VotingClassifier(estimators=[('lr', LogisticRegression()), ('knn', KNeighborsClassifier())])\n",
    "    eclf_grid = GridSearchCV(eclf, param_grid)\n",
    "    eclf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026515b-e9fe-4fce-9150-da54401955e8",
   "metadata": {},
   "source": [
    "## Random Forest Bagging\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_estimators\": range(100, 150, 10),\n",
    "        \"max_depth\": range(5,50,5),\n",
    "        \"min_samples_split\": np.arange(.1,.6,.1),\n",
    "        \"min_samples_leaf\": np.arange(.1,.6,.1),\n",
    "        \"max_features\": np.arange(0.1, 0.6, .1)\n",
    "    }\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    clf_grid = RandomizedSearchCV(clf, param_grid, n_iter=25)\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "\n",
    "### Plotting Feature Importance\n",
    "    feat_df = pd.DataFrame()\n",
    "    feat_df['feature'] = X_train.columns\n",
    "    feat_df['importance'] = clf_grid.best_estimator_.feature_importances_\n",
    "    feat_df = feat_df.sort_values('importance', ascending=False)\n",
    "    sns.barplot(y=feat_df['feature'], \n",
    "                x=feat_df['importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4340dd8-1fbe-4527-8463-4f36c5c68d0b",
   "metadata": {},
   "source": [
    "## XGB Boosting\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': range(100,500, 50),\n",
    "        'max_depth': range(5,50, 5),\n",
    "        'learning_rate': [0.1, 0.001, 0.00001, 1],\n",
    "        'gamma': np.arange(0.5, 2, .2),\n",
    "        'reg_alpha': [0, 0.5, 1],\n",
    "        'reg_lambda': [1, 1.5, 2, 3, 4.5]\n",
    "    }\n",
    "    \n",
    "    clf = xgb.XGBClassifier(objective='binary:logistic', eval_metric=\"logloss\", use_label_encoder=False)\n",
    "    clf_grid = RandomizedSearchCV(clf, params, n_iter=10)\n",
    "    clf_grid.fit(X_train, y_train)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1458c-bd82-439e-a153-6552bbda730a",
   "metadata": {},
   "source": [
    "# 5 Nerual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4fe839-5684-45d8-ac18-903c6d080fd5",
   "metadata": {},
   "source": [
    "    from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f6bfa-3944-4064-b246-2c6942bfd5cd",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "    from sklearn.pipeline import Pipeline \n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119869d6-955e-47bd-aa05-fe4b8e5d3c75",
   "metadata": {},
   "source": [
    "### Imputation\n",
    "    numeric_imputer = Pipeline(steps=[\n",
    "            ('impute', SimpleImputer(strategy=\"mean\"))\n",
    "    ])\n",
    "    \n",
    "    categorical_imputer = Pipeline(steps=[\n",
    "            ('impute', SimpleImputer(strategy=\"most_frequent\")),\n",
    "            ('one-hot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "\n",
    "#### Sample Imputation\n",
    "    # Call fit then transform\n",
    "    numeric_imputer.fit(X_train[cols])\n",
    "    numeric_imputer.transform(X_train[cols])\n",
    "\n",
    "### Combining Different Imputations\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    \n",
    "    numerical_features = X_train.select_dtypes(include='number').columns.tolist()\n",
    "    categorical_features = X_train.select_dtypes(include='object').columns.tolist()\n",
    "    \n",
    "    print(numerical_features)\n",
    "    print(categorical_features)\n",
    "    \n",
    "    num_cat_imputer = ColumnTransformer(transformers=[\n",
    "        ('numeric', numeric_imputer, numerical_features),\n",
    "        ('categorical', categorical_imputer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05621993-ba0f-4c4a-88a8-a69644a5827c",
   "metadata": {},
   "source": [
    "### Pipeline Making\n",
    "    log_reg = LogisticRegression()\n",
    "    \n",
    "    logreg_pipeline = Pipeline(steps=[\n",
    "        ('preprocess', num_cat_imputer),\n",
    "        ('model', log_reg)\n",
    "    ])\n",
    "    \n",
    "    logreg_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04ce55a-f107-4b8f-9dd1-788198aa0c98",
   "metadata": {},
   "source": [
    "### Multiple Models in Pipeline\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    param_dict = [\n",
    "        {\n",
    "            'classifier': [LogisticRegression()],\n",
    "            'classifier__C': [0.1, 0.001, 1],\n",
    "            'classifier__penalty': ['l1', 'l2'],\n",
    "            'classifier__solver': ['liblinear']     \n",
    "        },\n",
    "        {\n",
    "            'classifier': [RandomForestClassifier()],\n",
    "            'classifier__n_estimators': range(100, 200, 25),\n",
    "            'classifier__max_depth': range(10,50,10),\n",
    "            'classifier__min_samples_split': np.arange(0.1,.6,.15),\n",
    "            'classifier__min_samples_leaf': np.arange(0.1,.6,.15),\n",
    "            'classifier__max_features': np.arange(0.1,.6,.15)\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocess', num_cat_imputer),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    search = GridSearchCV(pipeline, param_dict, cv=10, verbose=0)\n",
    "    search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305f4913-9738-4bce-9695-c4c3b786bb4f",
   "metadata": {},
   "source": [
    "# Search Feature Importance Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0eefb1-2b6a-4f22-9007-efbba0c1cf27",
   "metadata": {},
   "source": [
    "    cols = X_train.columns.to_list()\n",
    "        fig, ax = plt.subplots(figsize=(15,10))\n",
    "        sns.barplot(x=clf_grid.best_estimator_.coef_[0], y=cols)\n",
    "        \n",
    "        for p in ax.patches:\n",
    "            width = p.get_width()    # get bar length\n",
    "            ax.text(width - .5,       # set the text at 1 unit right of the bar\n",
    "                    p.get_y() + p.get_height() / 2, # get Y coordinate + X coordinate / 2\n",
    "                    '{:1.2f}'.format(width), # set variable to display, 2 decimals\n",
    "                    ha = 'left',   # horizontal alignment\n",
    "                    va = 'center',\n",
    "                    fontsize=13)  # vertical alignmen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec4209e-21d5-4b7b-b337-9ee9693b769b",
   "metadata": {},
   "source": [
    "# Shap\n",
    "### Pipeline\n",
    "    import shap\n",
    "    explainer = shap.TreeExplainer(search.best_estimator_.steps[1][1], \n",
    "                                   search.best_estimator_.steps[0][1].transform(X_train),\n",
    "                                   feature_perturbation='interventional',\n",
    "                                   model_output='probability')\n",
    "    shap_values = explainer.shap_values(search.best_estimator_.steps[0][1].transform(X_test))\n",
    "    \n",
    "    shap.summary_plot(shap_values[:,:,0], search.best_estimator_.steps[0][1].transform(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
